{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>2154840872.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905</th>\n",
       "      <td>367487965.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>1654830882.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>2768884840.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14703</th>\n",
       "      <td>3636364733.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label\n",
       "6438   2154840872.jpg      3\n",
       "14905   367487965.jpg      3\n",
       "3703   1654830882.jpg      3\n",
       "9949   2768884840.jpg      2\n",
       "14703  3636364733.jpg      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_path = 'data/'\n",
    "df = pd.read_csv(general_path + 'train.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = df.to_numpy()\n",
    "image_list = train_list[:,0].astype(np.str)\n",
    "label_list = train_list[:,1].astype(np.uint8)\n",
    "data_list = np.column_stack((image_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(label_list, bins=np.arange(6)-0.5, density=False, cumulative=False, histtype='bar', rwidth=0.8)\n",
    "plt.xticks(range(5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_data(train_list):\n",
    "    '''\n",
    "        train_list[:][0] : image's file name\n",
    "        train_list[:][1] : image's label\n",
    "    '''\n",
    "    height = 456\n",
    "    width = 456\n",
    "    \n",
    "    length = train_list.shape[0]\n",
    "    ori_list = np.arange(length)\n",
    "    aug_list = np.random.choice(ori_list, length, replace=True)\n",
    "    \n",
    "    np.random.shuffle(ori_list)\n",
    "    np.random.shuffle(aug_list)\n",
    "    \n",
    "    zeros = np.zeros(length)\n",
    "    ones = np.ones(length)\n",
    "    is_aug = np.append(zeros, ones)\n",
    "    \n",
    "    total_list = np.append(ori_list, aug_list)\n",
    "    total_list = np.column_stack((total_list, is_aug)).astype(np.int32)\n",
    "    np.random.shuffle(total_list)\n",
    "    \n",
    "    for num, aug in total_list:\n",
    "        if aug == 0:\n",
    "            ori_img = tf.io.read_file(general_path + 'train_images/' + train_list[num][0].decode('utf-8'))\n",
    "            ori_img = tf.image.decode_jpeg(ori_img, channels=3)\n",
    "            img = tf.image.resize(ori_img, [456, 456])\n",
    "\n",
    "            label = int(train_list[num][1])\n",
    "            n_values = 5\n",
    "            one_hot = tf.eye(n_values)[label]\n",
    "\n",
    "            yield (tf.reshape(img, [1, height, width, 3]) / 255, tf.reshape(one_hot, [1, 5]))\n",
    "            \n",
    "        else:\n",
    "            \"\"\"\n",
    "                1) crop\n",
    "                2) rotate90\n",
    "                3) flip(horizon, vertical)\n",
    "                4) hue\n",
    "                5) brightness\n",
    "                6) constrast\n",
    "                7) clip\n",
    "            \"\"\"\n",
    "            rc = np.random.randint(0, 300)\n",
    "            rr = np.random.randint(0, 3)\n",
    "            \n",
    "            # load a image\n",
    "            ori_img = tf.io.read_file(general_path + 'train_images/' + train_list[num][0].decode('utf-8'))\n",
    "            \n",
    "            # decode a raw image\n",
    "            ori_img = tf.image.decode_jpeg(ori_img, channels=3)\n",
    "            \n",
    "            img_height, img_width, _ = ori_img.shape\n",
    "            \n",
    "            # 1) crop\n",
    "            img = tf.image.random_crop(ori_img, [img_height - rc, img_height - rc, 3])\n",
    "            \n",
    "            # 2) rotate90\n",
    "            img = tf.image.rot90(img, k=rr)\n",
    "            \n",
    "            # 3) flip(horizon, vertical)\n",
    "            img = tf.image.random_flip_left_right(img)\n",
    "            img = tf.image.random_flip_up_down(img)\n",
    "            \n",
    "            # 4) hue\n",
    "            img = tf.image.random_hue(img, 0.1)\n",
    "            \n",
    "            # 5) brightness\n",
    "            img = tf.image.random_brightness(img, 0.3)\n",
    "            \n",
    "            # 6) contrast\n",
    "            img = tf.image.random_contrast(img, 0.6, 1.8)\n",
    "            \n",
    "            # 7) clip\n",
    "            img = tf.clip_by_value(img, 0, 255)\n",
    "            \n",
    "            img = tf.image.resize(img, [456, 456])\n",
    "            \n",
    "            # one-hot encoding\n",
    "            label = int(train_list[num][1])\n",
    "            n_values = 5\n",
    "            one_hot = tf.eye(n_values)[label]\n",
    "\n",
    "            yield (tf.reshape(img, [1, height, width, 3]) / 255, tf.reshape(one_hot, [1, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_data_val(val_list):\n",
    "    height = 456\n",
    "    width = 456\n",
    "    \n",
    "    for image_name, label in val_list:\n",
    "        ori_img = tf.io.read_file(general_path + 'train_images/' + image.decode('utf-8'))\n",
    "        ori_img = tf.image.decode_jpeg(ori_img, channels=3)\n",
    "        img = tf.image.resize(ori_img, [456, 456])\n",
    "\n",
    "        label = int(label)\n",
    "        n_values = 5\n",
    "        one_hot = tf.eye(n_values)[label]\n",
    "\n",
    "        yield (tf.reshape(img, [1, height, width, 3]) / 255, tf.reshape(one_hot, [1, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Test code ***\n",
    "\n",
    "# rc = np.random.randint(0, 300)\n",
    "# rr = np.random.randint(0, 3)\n",
    "# ori_img = tf.io.read_file(general_path + 'train_images/' + '85453943.jpg')\n",
    "# ori_img = tf.image.decode_jpeg(ori_img, channels=3)\n",
    "# img_height, img_width, _ = ori_img.shape\n",
    "# img = tf.image.random_crop(ori_img, [img_height - rc, img_height - rc, 3])\n",
    "# img = tf.image.rot90(img, k=rr)\n",
    "# img = tf.image.random_flip_left_right(img)\n",
    "# img = tf.image.random_flip_up_down(img)\n",
    "# img = tf.image.random_hue(img, 0.1)\n",
    "# img = tf.image.random_brightness(img, 0.15)\n",
    "# img = tf.image.random_contrast(img, 0.8, 1.5)\n",
    "\n",
    "# img = tf.clip_by_value(img, 0, 255)\n",
    "# img = tf.image.resize(img, [456, 456])\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img / 255)\n",
    "# plt.title('augmented image')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(ori_img)\n",
    "# plt.title('original image')\n",
    "\n",
    "# plt.show()\n",
    "# print(tf.math.reduce_max(augmented_img))\n",
    "# print(tf.math.reduce_min(augmented_img))\n",
    "# print(tf.math.maximum(tf.reshape(augmented_img, [456*456*3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(456, 456, 3))\n",
    "effnet = tf.keras.applications.EfficientNetB5(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling='avg', classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 456, 456, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb5 (Functional)  (None, 2048)              28513527  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 28,523,772\n",
      "Trainable params: 28,351,029\n",
      "Non-trainable params: 172,743\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "effnet = tf.keras.layers.Dense(5, activation='softmax')(effnet)\n",
    "# effnet.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=effnet)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(lr=0.00005), metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train_validation\n",
    "\n",
    "np.random.shuffle(data_list)\n",
    "split_ratio = int(data_list.shape[0]*0.8)\n",
    "train_list = data_list[:split_ratio]\n",
    "val_list = data_list[split_ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# checkpoint\n",
    "\n",
    "checkpoint_path = \"data/checkpoint/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=1)\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(get_leaf_data,\n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=([None, 456, 456, 3], [None, 5]),\n",
    "                                         args=(train_list, ))\n",
    "\n",
    "val = tf.data.Dataset.from_generator(get_leaf_data_val,\n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=([None, 456, 456, 3], [None, 5]),\n",
    "                                         args=(val_list, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    120/Unknown - 22s 183ms/step - loss: 1.3597 - acc: 0.5333"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a9c11690082c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(dataset, validation_data=val, callbacks=[cp_callback], epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
